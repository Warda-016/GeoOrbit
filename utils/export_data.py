import pandas as pd
import json
from datetime import datetime
import streamlit as st
from io import BytesIO

def export_to_csv(issues_df, filename="lahore_issues.csv"):
    """Export issues data to CSV"""
    try:
        csv_data = issues_df.to_csv(index=False)
        return csv_data.encode('utf-8')
    except Exception as e:
        st.error(f"Error exporting to CSV: {str(e)}")
        return None

def export_to_json(issues_df, filename="lahore_issues.json"):
    """Export issues data to JSON"""
    try:
        json_data = issues_df.to_json(orient='records', indent=2)
        return json_data.encode('utf-8')
    except Exception as e:
        st.error(f"Error exporting to JSON: {str(e)}")
        return None

def generate_summary_report(issues_df):
    """Generate a text summary report"""
    if issues_df.empty:
        return "No data available for report generation."
    
    report = f"""
LAHORE ENVIRONMENTAL & SOCIAL ISSUES MAPPER
Summary Report
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*60}

OVERALL STATISTICS
{'='*60}
Total Issues Reported: {len(issues_df)}
Open Issues: {len(issues_df[issues_df['status'] == 'Open'])}
In Progress: {len(issues_df[issues_df['status'] == 'In Progress'])}
Resolved Issues: {len(issues_df[issues_df['status'] == 'Resolved'])}
Closed Issues: {len(issues_df[issues_df['status'] == 'Closed'])}

SEVERITY BREAKDOWN
{'='*60}
"""
    
    for severity in ['Critical', 'High', 'Medium', 'Low']:
        count = len(issues_df[issues_df['severity'] == severity])
        report += f"{severity}: {count}\n"
    
    report += f"\nISSUE TYPES DISTRIBUTION\n{'='*60}\n"
    type_counts = issues_df['type'].value_counts()
    for issue_type, count in type_counts.items():
        report += f"{issue_type}: {count}\n"
    
    report += f"\nTOP AFFECTED LOCATIONS\n{'='*60}\n"
    location_counts = issues_df['location'].value_counts().head(10)
    for location, count in location_counts.items():
        report += f"{location}: {count} issues\n"
    
    report += f"\nRECENT ISSUES (Last 10)\n{'='*60}\n"
    recent = issues_df.sort_values('date_reported', ascending=False).head(10)
    for _, issue in recent.iterrows():
        report += f"\nID: {issue['id']} | {issue['title']}\n"
        report += f"  Type: {issue['type']} | Severity: {issue['severity']} | Status: {issue['status']}\n"
        report += f"  Location: {issue['location']} | Date: {issue['date_reported']}\n"
    
    report += f"\n{'='*60}\n"
    report += "Report generated by Lahore Environmental & Social Issues Mapper\n"
    report += "NASA Space Apps Challenge 2025\n"
    
    return report

def create_filtered_export(issues_df, filters):
    """Create export with applied filters"""
    filtered_df = issues_df.copy()
    
    if filters.get('type') and filters['type'] != 'All':
        filtered_df = filtered_df[filtered_df['type'] == filters['type']]
    
    if filters.get('severity') and filters['severity'] != 'All':
        filtered_df = filtered_df[filtered_df['severity'] == filters['severity']]
    
    if filters.get('status') and filters['status'] != 'All':
        filtered_df = filtered_df[filtered_df['status'] == filters['status']]
    
    if filters.get('date_range'):
        start_date, end_date = filters['date_range']
        filtered_df['date_reported'] = pd.to_datetime(filtered_df['date_reported'])
        filtered_df = filtered_df[
            (filtered_df['date_reported'] >= start_date) & 
            (filtered_df['date_reported'] <= end_date)
        ]
    
    return filtered_df

def export_analytics_report(issues_df):
    """Generate detailed analytics report"""
    if issues_df.empty:
        return "No data available for analytics."
    
    df = issues_df.copy()
    df['date_reported'] = pd.to_datetime(df['date_reported'], errors='coerce')
    
    report = f"""
LAHORE ISSUES MAPPER - DETAILED ANALYTICS REPORT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*70}

1. TEMPORAL ANALYSIS
{'='*70}
Total Reporting Period: {df['date_reported'].min()} to {df['date_reported'].max()}
Average Issues per Day: {len(df) / max(1, (df['date_reported'].max() - df['date_reported'].min()).days):.2f}

Monthly Distribution:
"""
    
    df['month'] = df['date_reported'].dt.to_period('M')
    monthly = df.groupby('month').size()
    for month, count in monthly.items():
        report += f"  {month}: {count} issues\n"
    
    report += f"\n2. SEVERITY ANALYSIS\n{'='*70}\n"
    severity_stats = df.groupby('severity').agg({
        'id': 'count',
        'status': lambda x: (x == 'Resolved').sum()
    })
    severity_stats.columns = ['Total', 'Resolved']
    severity_stats['Resolution Rate'] = (severity_stats['Resolved'] / severity_stats['Total'] * 100).round(1)
    report += severity_stats.to_string()
    
    report += f"\n\n3. GEOGRAPHIC ANALYSIS\n{'='*70}\n"
    report += f"Unique Locations: {df['location'].nunique()}\n"
    report += f"Most Affected Areas:\n"
    top_locations = df['location'].value_counts().head(5)
    for location, count in top_locations.items():
        report += f"  {location}: {count} issues\n"
    
    report += f"\n4. ISSUE TYPE TRENDS\n{'='*70}\n"
    type_severity = pd.crosstab(df['type'], df['severity'])
    report += type_severity.to_string()
    
    report += f"\n\n5. RESOLUTION METRICS\n{'='*70}\n"
    total = len(df)
    resolved = len(df[df['status'] == 'Resolved'])
    in_progress = len(df[df['status'] == 'In Progress'])
    open_issues = len(df[df['status'] == 'Open'])
    
    report += f"Total Issues: {total}\n"
    report += f"Resolved: {resolved} ({resolved/total*100:.1f}%)\n"
    report += f"In Progress: {in_progress} ({in_progress/total*100:.1f}%)\n"
    report += f"Open: {open_issues} ({open_issues/total*100:.1f}%)\n"
    
    report += f"\n{'='*70}\n"
    report += "End of Analytics Report\n"
    
    return report
